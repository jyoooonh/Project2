{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../datasets/unlisted_filled_train_data.csv')\n",
    "test = pd.read_csv('../../datasets/unlisted_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_life_cycle = train[['도입기', '성장기', '성숙기', '쇠퇴기']]\n",
    "# test_life_cycle = test[['도입기', '성장기', '성숙기', '쇠퇴기']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['CASH FLOW 대 부채비율', 'CASH FLOW 대 총자본비율', 'CASH FLOW 대 매출액비율', '차입금의존도', '순운전자본비율',\n",
    "                     '자기자본구성비율', '경영자본순이익률', '총자본사업이익률', '총자본영업이익률', '금융비용부담률', \n",
    "                     '매출액증가율', '이윤분배율', '총자본회전률', '영업년수', \n",
    "                     '도입기', '성장기', '성숙기', '쇠퇴기']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[selected_features]\n",
    "x_test = test[selected_features]\n",
    "\n",
    "y_train = train['부실판단']\n",
    "y_test = test['부실판단']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.fillna(test['영업년수'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.69436374 0.74607786 0.78139535 0.7244186  0.68372093]\n",
      "CV_Precision_Scores: [0.67803838 0.75059102 0.83798883 0.72494172 0.66458333]\n",
      "CV_Recall_Scores: [0.73953488 0.73751452 0.69767442 0.72325581 0.74186047]\n",
      "CV_F1_Scores: [0.70745273 0.74399531 0.76142132 0.72409779 0.7010989 ]\n",
      "CV_ROC/AUC: [0.75433379 0.82344489 0.87410357 0.80359519 0.74659681]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.726\n",
      "CV_Precision_mean: 0.731\n",
      "CV_Recall_mean: 0.728\n",
      "CV_F1_스코어_mean: 0.728\n",
      "CV_ROC_AUC+스코어_mean: 0.800\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.753\n",
      "Precision: 0.647\n",
      "Recall: 0.727\n",
      "F1 스코어: 0.684\n",
      "ROC AUC 스코어: 0.748\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'F1 스코어: {f1:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.823\n",
      "Precision: 0.729\n",
      "Recall: 0.827\n",
      "F1 스코어: 0.775\n",
      "ROC AUC 스코어: 0.824\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 모델 생성 및 학습\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=29, min_samples_split=7, min_samples_leaf=8, max_depth=7)\n",
    "\n",
    "# # Cross Validation\n",
    "# cv_accuracy = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "# cv_precision = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='precision')\n",
    "# cv_recall = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='recall')\n",
    "# cv_f1 = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='f1')\n",
    "# cv_roc_auc = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "# print(\"CV_Precision_Scores:\", cv_precision)\n",
    "# print(\"CV_Recall_Scores:\", cv_recall)\n",
    "# print(\"CV_F1_Scores:\", cv_f1)\n",
    "# print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "# print('\\n=======교차검증 결과=======')\n",
    "# print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "# print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "# print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "# print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "# print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_rf:.3f}')\n",
    "print(f'Precision: {precision_rf:.3f}')\n",
    "print(f'Recall: {recall_rf:.3f}')\n",
    "print(f'F1 스코어: {f1_rf:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_rf:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.72051133 0.78094131 0.83255814 0.78081395 0.71976744]\n",
      "CV_Precision_Scores: [0.71607754 0.79876543 0.85929648 0.77288136 0.7090708 ]\n",
      "CV_Recall_Scores: [0.73023256 0.7514518  0.79534884 0.79534884 0.74534884]\n",
      "CV_F1_Scores: [0.72308578 0.77438659 0.82608696 0.78395415 0.72675737]\n",
      "CV_ROC/AUC: [0.80820368 0.87892864 0.91517645 0.87009194 0.80805368]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.767\n",
      "CV_Precision_mean: 0.771\n",
      "CV_Recall_mean: 0.764\n",
      "CV_F1_스코어_mean: 0.767\n",
      "CV_ROC_AUC+스코어_mean: 0.856\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.775\n",
      "Precision: 0.678\n",
      "Recall: 0.741\n",
      "F1 스코어: 0.708\n",
      "ROC AUC 스코어: 0.768\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost 모델 생성 및 학습\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "adaboost_model.fit(x_train, y_train)\n",
    "y_pred_adaboost = adaboost_model.predict(x_test)\n",
    "\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "precision_adaboost = precision_score(y_test, y_pred_adaboost)\n",
    "recall_adaboost = recall_score(y_test, y_pred_adaboost)\n",
    "f1_adaboost = f1_score(y_test, y_pred_adaboost)\n",
    "roc_auc_adaboost = roc_auc_score(y_test, y_pred_adaboost)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_adaboost:.3f}')\n",
    "print(f'Precision: {precision_adaboost:.3f}')\n",
    "print(f'Recall: {recall_adaboost:.3f}')\n",
    "print(f'F1 스코어: {f1_adaboost:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_adaboost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.816\n",
      "Precision: 0.717\n",
      "Recall: 0.827\n",
      "F1 스코어: 0.768\n",
      "ROC AUC 스코어: 0.819\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "\n",
    "xgboost_model.fit(x_train, y_train)\n",
    "y_pred_xgboost = xgboost_model.predict(x_test)\n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "precision_xgboost = precision_score(y_test, y_pred_xgboost)\n",
    "recall_xgboost = recall_score(y_test, y_pred_xgboost)\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost)\n",
    "roc_auc_xgboost = roc_auc_score(y_test, y_pred_xgboost)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_xgboost:.3f}')\n",
    "print(f'Precision: {precision_xgboost:.3f}')\n",
    "print(f'Recall: {recall_xgboost:.3f}')\n",
    "print(f'F1 스코어: {f1_xgboost:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_xgboost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.71121441 0.77222545 0.87674419 0.775      0.7       ]\n",
      "CV_Precision_Scores: [0.70872642 0.77546012 0.88409091 0.78355502 0.71038961]\n",
      "CV_Recall_Scores: [0.64534884 0.78164925 0.86860465 0.75697674 0.65581395]\n",
      "CV_F1_Scores: [0.71194379 0.76460177 0.86470588 0.76421801 0.66056166]\n",
      "CV_ROC/AUC: [0.78085514 0.85297248 0.93707883 0.85159208 0.76191117]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.767\n",
      "CV_Precision_mean: 0.772\n",
      "CV_Recall_mean: 0.742\n",
      "CV_F1_스코어_mean: 0.753\n",
      "CV_ROC_AUC+스코어_mean: 0.837\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.817\n",
      "Precision: 0.735\n",
      "Recall: 0.787\n",
      "F1 스코어: 0.760\n",
      "ROC AUC 스코어: 0.811\n"
     ]
    }
   ],
   "source": [
    "# Bagging 모델 생성 및 학습\n",
    "bagging_model = BaggingClassifier()\n",
    "\n",
    "cv_accuracy = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "bagging_model.fit(x_train, y_train)\n",
    "y_pred_bagging = bagging_model.predict(x_test)\n",
    "\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "precision_bagging = precision_score(y_test, y_pred_bagging)\n",
    "recall_bagging = recall_score(y_test, y_pred_bagging)\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging)\n",
    "roc_auc_bagging = roc_auc_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_bagging:.3f}')\n",
    "print(f'Precision: {precision_bagging:.3f}')\n",
    "print(f'Recall: {recall_bagging:.3f}')\n",
    "print(f'F1 스코어: {f1_bagging:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_bagging:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.70075537 0.75537478 0.79418605 0.75       0.66627907]\n",
      "CV_Precision_Scores: [0.71589487 0.75404157 0.75922131 0.73730684 0.6778607 ]\n",
      "CV_Recall_Scores: [0.66511628 0.75842044 0.86162791 0.77674419 0.63372093]\n",
      "CV_F1_Scores: [0.68957203 0.75622467 0.80718954 0.75651189 0.65504808]\n",
      "CV_ROC/AUC: [0.75942117 0.83432056 0.88023797 0.81419957 0.7403556 ]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.733\n",
      "CV_Precision_mean: 0.729\n",
      "CV_Recall_mean: 0.739\n",
      "CV_F1_스코어_mean: 0.733\n",
      "CV_ROC_AUC+스코어_mean: 0.806\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.728\n",
      "Precision: 0.613\n",
      "Recall: 0.713\n",
      "F1 스코어: 0.659\n",
      "ROC AUC 스코어: 0.725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM 모델 생성 및 학습\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "cv_accuracy = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_svm:.3f}')\n",
    "print(f'Precision: {precision_svm:.3f}')\n",
    "print(f'Recall: {recall_svm:.3f}')\n",
    "print(f'F1 스코어: {f1_svm:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_svm:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.69029634 0.75479372 0.775      0.71162791 0.66918605]\n",
      "CV_Precision_Scores: [0.66666667 0.74971559 0.89220564 0.72921914 0.65832427]\n",
      "CV_Recall_Scores: [0.76046512 0.76538908 0.6255814  0.67325581 0.70348837]\n",
      "CV_F1_Scores: [0.71048343 0.75747126 0.73547505 0.70012092 0.68015739]\n",
      "CV_ROC/AUC: [0.74460335 0.82865516 0.89323283 0.79735533 0.73578826]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.720\n",
      "CV_Precision_mean: 0.739\n",
      "CV_Recall_mean: 0.706\n",
      "CV_F1_스코어_mean: 0.717\n",
      "CV_ROC_AUC+스코어_mean: 0.800\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.771\n",
      "Precision: 0.678\n",
      "Recall: 0.719\n",
      "F1 스코어: 0.698\n",
      "ROC AUC 스코어: 0.760\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM 모델 생성 및 학습\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "cv_accuracy = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_svm:.3f}')\n",
    "print(f'Precision: {precision_svm:.3f}')\n",
    "print(f'Recall: {recall_svm:.3f}')\n",
    "print(f'F1 스코어: {f1_svm:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_svm:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000291\n",
      "[LightGBM] [Info] Start training from score 0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3440, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000291\n",
      "[LightGBM] [Info] Start training from score -0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000291\n",
      "[LightGBM] [Info] Start training from score 0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3440, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000291\n",
      "[LightGBM] [Info] Start training from score -0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000291\n",
      "[LightGBM] [Info] Start training from score 0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3440, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000291\n",
      "[LightGBM] [Info] Start training from score -0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000291\n",
      "[LightGBM] [Info] Start training from score 0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3440, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000291\n",
      "[LightGBM] [Info] Start training from score -0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500073 -> initscore=0.000291\n",
      "[LightGBM] [Info] Start training from score 0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3440, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6881, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499927 -> initscore=-0.000291\n",
      "[LightGBM] [Info] Start training from score -0.000291\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3379\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 3441, number of negative: 3441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3378\n",
      "[LightGBM] [Info] Number of data points in the train set: 6882, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.74317257 0.81580476 0.9        0.80697674 0.71569767]\n",
      "CV_Precision_Scores: [0.72916667 0.79501085 0.87554585 0.79596413 0.70054054]\n",
      "CV_Recall_Scores: [0.77325581 0.85133566 0.93255814 0.8255814  0.75348837]\n",
      "CV_F1_Scores: [0.75056433 0.82220976 0.90315315 0.81050228 0.72605042]\n",
      "CV_ROC/AUC: [0.83584799 0.90416228 0.9583775  0.90447674 0.80771904]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.796\n",
      "CV_Precision_mean: 0.779\n",
      "CV_Recall_mean: 0.827\n",
      "CV_F1_스코어_mean: 0.802\n",
      "CV_ROC_AUC+스코어_mean: 0.882\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4301, number of negative: 4301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3380\n",
      "[LightGBM] [Info] Number of data points in the train set: 8602, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.817\n",
      "Precision: 0.722\n",
      "Recall: 0.819\n",
      "F1 스코어: 0.767\n",
      "ROC AUC 스코어: 0.818\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LGBM 모델 생성 및 학습\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "cv_accuracy = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "lgbm_model.fit(x_train, y_train)\n",
    "y_pred_lgbm = lgbm_model.predict(x_test)\n",
    "\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "precision_lgbm = precision_score(y_test, y_pred_lgbm)\n",
    "recall_lgbm = recall_score(y_test, y_pred_lgbm)\n",
    "f1_lgbm = f1_score(y_test, y_pred_lgbm)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_lgbm:.3f}')\n",
    "print(f'Precision: {precision_lgbm:.3f}')\n",
    "print(f'Recall: {recall_lgbm:.3f}')\n",
    "print(f'F1 스코어: {f1_lgbm:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_lgbm:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(256, input_dim = 12, activation = 'relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation = 'relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(x_train, y_train, epochs=200, batch_size=5)\n",
    "\n",
    "# print(\"\\n Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델을 사용하여 테스트 데이터에 대한 예측 수행\n",
    "# y_pred = model.predict(x_test)\n",
    "# y_pred = binarize(y_pred, threshold=0.5)  # 예측값을 0.5 임계값을 기준으로 이진 분류로 변환\n",
    "\n",
    "# # 정확도(accuracy) 계산\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # F1 점수(f1 score) 계산\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# # 재현율(recall) 계산\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# print(f\"recall: {recall:.4f}\")\n",
    "\n",
    "# # 정밀도(precision) 계산\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# print(f\"precision: {precision:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
