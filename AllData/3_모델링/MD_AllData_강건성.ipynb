{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../datasets/all_data_filled_train_data.csv')\n",
    "test = pd.read_csv('../../datasets/all_data_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_life_cycle = train[['도입기', '성장기', '성숙기', '쇠퇴기']]\n",
    "# test_life_cycle = test[['도입기', '성장기', '성숙기', '쇠퇴기']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['CASH FLOW 대 부채비율', 'CASH FLOW 대 총자본비율', 'CASH FLOW 대 매출액비율', '차입금의존도', '순운전자본비율',\n",
    "                     '자기자본구성비율', '경영자본순이익률', '총자본사업이익률', '총자본영업이익률', '금융비용부담률', \n",
    "                     '매출액증가율', '이윤분배율', '총자본회전률', '영업년수', \n",
    "                     '도입기', '성장기', '성숙기', '쇠퇴기']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[selected_features]\n",
    "x_test = test[selected_features]\n",
    "\n",
    "y_train = train['부실판단']\n",
    "y_test = test['부실판단']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.fillna(test['영업년수'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_Accuracy_Scores: [0.70091324 0.81023065 0.83238182 0.82050697 0.71157799]\n",
      "CV_Precision_Scores: [0.68691589 0.80919854 0.80074411 0.81880109 0.67353051]\n",
      "CV_Recall_Scores: [0.73835616 0.8117862  0.88487894 0.82328767 0.82146119]\n",
      "CV_F1_Scores: [0.71170775 0.81049031 0.84071181 0.82103825 0.74017692]\n",
      "CV_ROC/AUC: [0.76411293 0.88872173 0.90875194 0.90097999 0.76688882]\n",
      "\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_mean: 0.775\n",
      "CV_Precision_mean: 0.758\n",
      "CV_Recall_mean: 0.816\n",
      "CV_F1_스코어_mean: 0.785\n",
      "CV_ROC_AUC+스코어_mean: 0.846\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.747\n",
      "Precision: 0.644\n",
      "Recall: 0.720\n",
      "F1 스코어: 0.679\n",
      "ROC AUC 스코어: 0.741\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(logit_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 결과=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "logit_model.fit(x_train, y_train)\n",
    "y_pred = logit_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')\n",
    "print(f'F1 스코어: {f1:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.835\n",
      "Precision: 0.742\n",
      "Recall: 0.856\n",
      "F1 스코어: 0.795\n",
      "ROC AUC 스코어: 0.840\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 모델 생성 및 학습\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=29, min_samples_split=7, min_samples_leaf=8, max_depth=7)\n",
    "\n",
    "# # Cross Validation\n",
    "# cv_accuracy = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "# cv_precision = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='precision')\n",
    "# cv_recall = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='recall')\n",
    "# cv_f1 = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='f1')\n",
    "# cv_roc_auc = cross_val_score(rf_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "# print(\"CV_Precision_Scores:\", cv_precision)\n",
    "# print(\"CV_Recall_Scores:\", cv_recall)\n",
    "# print(\"CV_F1_Scores:\", cv_f1)\n",
    "# print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "# print('\\n=======교차검증 결과=======')\n",
    "# print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "# print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "# print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "# print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "# print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_rf:.3f}')\n",
    "print(f'Precision: {precision_rf:.3f}')\n",
    "print(f'Recall: {recall_rf:.3f}')\n",
    "print(f'F1 스코어: {f1_rf:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_rf:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.71347032 0.85316282 0.88193652 0.88650377 0.7218543 ]\n",
      "CV_Precision_Scores: [0.68828031 0.83261618 0.88069217 0.88600091 0.68381241]\n",
      "CV_Recall_Scores: [0.7803653  0.88396528 0.88350845 0.88721461 0.82557078]\n",
      "CV_F1_Scores: [0.73143591 0.85752271 0.88209806 0.88660735 0.74803475]\n",
      "CV_ROC/AUC: [0.79298107 0.92331239 0.9446504  0.95237072 0.78994798]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.811\n",
      "CV_Precision_mean: 0.794\n",
      "CV_Recall_mean: 0.852\n",
      "CV_F1_스코어_mean: 0.821\n",
      "CV_ROC_AUC+스코어_mean: 0.881\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.788\n",
      "Precision: 0.692\n",
      "Recall: 0.775\n",
      "F1 스코어: 0.732\n",
      "ROC AUC 스코어: 0.785\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost 모델 생성 및 학습\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "\n",
    "# Cross Validation\n",
    "cv_accuracy = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(adaboost_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "adaboost_model.fit(x_train, y_train)\n",
    "y_pred_adaboost = adaboost_model.predict(x_test)\n",
    "\n",
    "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
    "precision_adaboost = precision_score(y_test, y_pred_adaboost)\n",
    "recall_adaboost = recall_score(y_test, y_pred_adaboost)\n",
    "f1_adaboost = f1_score(y_test, y_pred_adaboost)\n",
    "roc_auc_adaboost = roc_auc_score(y_test, y_pred_adaboost)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_adaboost:.3f}')\n",
    "print(f'Precision: {precision_adaboost:.3f}')\n",
    "print(f'Recall: {recall_adaboost:.3f}')\n",
    "print(f'F1 스코어: {f1_adaboost:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_adaboost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.875\n",
      "Precision: 0.807\n",
      "Recall: 0.873\n",
      "F1 스코어: 0.838\n",
      "ROC AUC 스코어: 0.874\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = XGBClassifier()\n",
    "\n",
    "xgboost_model.fit(x_train, y_train)\n",
    "y_pred_xgboost = xgboost_model.predict(x_test)\n",
    "\n",
    "accuracy_xgboost = accuracy_score(y_test, y_pred_xgboost)\n",
    "precision_xgboost = precision_score(y_test, y_pred_xgboost)\n",
    "recall_xgboost = recall_score(y_test, y_pred_xgboost)\n",
    "f1_xgboost = f1_score(y_test, y_pred_xgboost)\n",
    "roc_auc_xgboost = roc_auc_score(y_test, y_pred_xgboost)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_xgboost:.3f}')\n",
    "print(f'Precision: {precision_xgboost:.3f}')\n",
    "print(f'Recall: {recall_xgboost:.3f}')\n",
    "print(f'F1 스코어: {f1_xgboost:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_xgboost:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.70639269 0.84425668 0.90888331 0.92943594 0.70792418]\n",
      "CV_Precision_Scores: [0.7288049  0.85036496 0.91232877 0.91543624 0.69201359]\n",
      "CV_Recall_Scores: [0.67762557 0.84833257 0.91411603 0.94018265 0.73196347]\n",
      "CV_F1_Scores: [0.69005011 0.84005563 0.91332117 0.92352941 0.71867294]\n",
      "CV_ROC/AUC: [0.79112383 0.91669295 0.96420542 0.96801108 0.78183925]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.819\n",
      "CV_Precision_mean: 0.820\n",
      "CV_Recall_mean: 0.822\n",
      "CV_F1_스코어_mean: 0.817\n",
      "CV_ROC_AUC+스코어_mean: 0.884\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.924\n",
      "Precision: 0.899\n",
      "Recall: 0.897\n",
      "F1 스코어: 0.898\n",
      "ROC AUC 스코어: 0.918\n"
     ]
    }
   ],
   "source": [
    "# Bagging 모델 생성 및 학습\n",
    "bagging_model = BaggingClassifier()\n",
    "\n",
    "cv_accuracy = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(bagging_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "bagging_model.fit(x_train, y_train)\n",
    "y_pred_bagging = bagging_model.predict(x_test)\n",
    "\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "precision_bagging = precision_score(y_test, y_pred_bagging)\n",
    "recall_bagging = recall_score(y_test, y_pred_bagging)\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging)\n",
    "roc_auc_bagging = roc_auc_score(y_test, y_pred_bagging)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_bagging:.3f}')\n",
    "print(f'Precision: {precision_bagging:.3f}')\n",
    "print(f'Recall: {recall_bagging:.3f}')\n",
    "print(f'F1 스코어: {f1_bagging:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_bagging:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # SVM 모델 생성 및 학습\n",
    "# svm_model = SVC(kernel='linear')\n",
    "\n",
    "# cv_accuracy = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "# cv_precision = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "# cv_recall = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "# cv_f1 = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "# cv_roc_auc = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# print('=======교차검증 결과=======')\n",
    "# print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "# print(\"CV_Precision_Scores:\", cv_precision)\n",
    "# print(\"CV_Recall_Scores:\", cv_recall)\n",
    "# print(\"CV_F1_Scores:\", cv_f1)\n",
    "# print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "# print('\\n=======교차검증 평균값=======')\n",
    "# print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "# print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "# print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "# print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "# print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "# svm_model.fit(x_train, y_train)\n",
    "# y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "# accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# precision_svm = precision_score(y_test, y_pred_svm)\n",
    "# recall_svm = recall_score(y_test, y_pred_svm)\n",
    "# f1_svm = f1_score(y_test, y_pred_svm)\n",
    "# roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "# print(f'\\n=======Test 데이터 평가======')\n",
    "# print(f'Accuracy: {accuracy_svm:.3f}')\n",
    "# print(f'Precision: {precision_svm:.3f}')\n",
    "# print(f'Recall: {recall_svm:.3f}')\n",
    "# print(f'F1 스코어: {f1_svm:.3f}')\n",
    "# print(f'ROC AUC 스코어: {roc_auc_svm:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # SVM 모델 생성 및 학습\n",
    "# svm_model = SVC(kernel='rbf')\n",
    "\n",
    "# cv_accuracy = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "# cv_precision = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "# cv_recall = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "# cv_f1 = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "# cv_roc_auc = cross_val_score(svm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "# print('=======교차검증 결과=======')\n",
    "# print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "# print(\"CV_Precision_Scores:\", cv_precision)\n",
    "# print(\"CV_Recall_Scores:\", cv_recall)\n",
    "# print(\"CV_F1_Scores:\", cv_f1)\n",
    "# print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "# print('\\n=======교차검증 평균값=======')\n",
    "# print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "# print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "# print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "# print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "# print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "# svm_model.fit(x_train, y_train)\n",
    "# y_pred_svm = svm_model.predict(x_test)\n",
    "\n",
    "# accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# precision_svm = precision_score(y_test, y_pred_svm)\n",
    "# recall_svm = recall_score(y_test, y_pred_svm)\n",
    "# f1_svm = f1_score(y_test, y_pred_svm)\n",
    "# roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "\n",
    "# print(f'\\n=======Test 데이터 평가======')\n",
    "# print(f'Accuracy: {accuracy_svm:.3f}')\n",
    "# print(f'Precision: {precision_svm:.3f}')\n",
    "# print(f'Recall: {recall_svm:.3f}')\n",
    "# print(f'F1 스코어: {f1_svm:.3f}')\n",
    "# print(f'ROC AUC 스코어: {roc_auc_svm:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 17516, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 17516, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 17516, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 17516, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3575\n",
      "[LightGBM] [Info] Number of data points in the train set: 17516, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8759, number of negative: 8758\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 8758, number of negative: 8759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3577\n",
      "[LightGBM] [Info] Number of data points in the train set: 17517, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499971 -> initscore=-0.000114\n",
      "[LightGBM] [Info] Start training from score -0.000114\n",
      "=======교차검증 결과=======\n",
      "CV_Accuracy_Scores: [0.72876712 0.87485727 0.93012103 0.93902718 0.73007536]\n",
      "CV_Precision_Scores: [0.71192893 0.84781687 0.91714665 0.91533477 0.68791946]\n",
      "CV_Recall_Scores: [0.76849315 0.91365921 0.94563728 0.96757991 0.84246575]\n",
      "CV_F1_Scores: [0.73913043 0.87950748 0.93117409 0.94073252 0.75738916]\n",
      "CV_ROC/AUC: [0.8196322  0.94723785 0.97718814 0.98168718 0.82420488]\n",
      "\n",
      "=======교차검증 평균값=======\n",
      "CV_Accuracy_mean: 0.841\n",
      "CV_Precision_mean: 0.816\n",
      "CV_Recall_mean: 0.888\n",
      "CV_F1_스코어_mean: 0.850\n",
      "CV_ROC_AUC+스코어_mean: 0.910\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 10948, number of negative: 10948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3578\n",
      "[LightGBM] [Info] Number of data points in the train set: 21896, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "=======Test 데이터 평가======\n",
      "Accuracy: 0.846\n",
      "Precision: 0.768\n",
      "Recall: 0.841\n",
      "F1 스코어: 0.803\n",
      "ROC AUC 스코어: 0.845\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LGBM 모델 생성 및 학습\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "cv_accuracy = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='accuracy')\n",
    "cv_precision = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='precision')\n",
    "cv_recall = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='recall')\n",
    "cv_f1 = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='f1')\n",
    "cv_roc_auc = cross_val_score(lgbm_model, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('=======교차검증 결과=======')\n",
    "print(\"CV_Accuracy_Scores:\", cv_accuracy)\n",
    "print(\"CV_Precision_Scores:\", cv_precision)\n",
    "print(\"CV_Recall_Scores:\", cv_recall)\n",
    "print(\"CV_F1_Scores:\", cv_f1)\n",
    "print(\"CV_ROC/AUC:\", cv_roc_auc)\n",
    "\n",
    "print('\\n=======교차검증 평균값=======')\n",
    "print(f'CV_Accuracy_mean: {cv_accuracy.mean():.3f}')\n",
    "print(f'CV_Precision_mean: {cv_precision.mean():.3f}')\n",
    "print(f'CV_Recall_mean: {cv_recall.mean():.3f}')\n",
    "print(f'CV_F1_스코어_mean: {cv_f1.mean():.3f}')\n",
    "print(f'CV_ROC_AUC+스코어_mean: {cv_roc_auc.mean():.3f}')\n",
    "\n",
    "lgbm_model.fit(x_train, y_train)\n",
    "y_pred_lgbm = lgbm_model.predict(x_test)\n",
    "\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "precision_lgbm = precision_score(y_test, y_pred_lgbm)\n",
    "recall_lgbm = recall_score(y_test, y_pred_lgbm)\n",
    "f1_lgbm = f1_score(y_test, y_pred_lgbm)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(f'\\n=======Test 데이터 평가======')\n",
    "print(f'Accuracy: {accuracy_lgbm:.3f}')\n",
    "print(f'Precision: {precision_lgbm:.3f}')\n",
    "print(f'Recall: {recall_lgbm:.3f}')\n",
    "print(f'F1 스코어: {f1_lgbm:.3f}')\n",
    "print(f'ROC AUC 스코어: {roc_auc_lgbm:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
